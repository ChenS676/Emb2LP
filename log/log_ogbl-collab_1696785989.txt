Namespace(device=1, encoder='HLGNN', predictor='MLP', optimizer='Adam', loss_func='AUC', neg_sampler='global', data_name='ogbl-collab', data_path='/home/zhangjuzheng/dataset', eval_metric='hits', walk_start_type='edge', res_dir='log', pretrain_emb=None, gnn_num_layers=15, mlp_num_layers=2, emb_hidden_channels=256, gnn_hidden_channels=256, mlp_hidden_channels=256, dropout=0.3, grad_clip_norm=2.0, batch_size=65536, lr=0.001, num_neg=1, walk_length=5, epochs=500, log_steps=1, eval_steps=5, runs=1, year=2010, use_lr_decay=False, use_node_feats=True, use_coalesce=False, train_node_emb=False, use_valedges_as_input=False, eval_last_best=False, random_walk_augment=False, alpha=0.5, init='NPPR')
Total number of model parameters is 99089
Hits@20
Run: 01, Epoch: 05, Loss: 13788.3577, Learning Rate: 0.0010, Valid: 4.69%, Test: 4.27%
Hits@50
Run: 01, Epoch: 05, Loss: 13788.3577, Learning Rate: 0.0010, Valid: 9.11%, Test: 7.82%
Hits@100
Run: 01, Epoch: 05, Loss: 13788.3577, Learning Rate: 0.0010, Valid: 14.37%, Test: 12.25%
Hits@20
Run: 01, Epoch: 10, Loss: 6803.8399, Learning Rate: 0.0010, Valid: 17.92%, Test: 16.26%
Hits@50
Run: 01, Epoch: 10, Loss: 6803.8399, Learning Rate: 0.0010, Valid: 31.54%, Test: 27.99%
Hits@100
Run: 01, Epoch: 10, Loss: 6803.8399, Learning Rate: 0.0010, Valid: 40.40%, Test: 36.12%
Hits@20
Run: 01, Epoch: 15, Loss: 6017.9172, Learning Rate: 0.0010, Valid: 23.05%, Test: 20.62%
Hits@50
Run: 01, Epoch: 15, Loss: 6017.9172, Learning Rate: 0.0010, Valid: 35.40%, Test: 30.85%
Hits@100
Run: 01, Epoch: 15, Loss: 6017.9172, Learning Rate: 0.0010, Valid: 42.23%, Test: 37.70%
