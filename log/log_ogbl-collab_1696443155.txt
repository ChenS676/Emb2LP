Namespace(device=1, encoder='HLGNN', predictor='MLP', optimizer='Adam', loss_func='AUC', neg_sampler='global', data_name='ogbl-collab', data_path='/home/zhangjuzheng/dataset', eval_metric='hits', walk_start_type='edge', res_dir='log', pretrain_emb=None, gnn_num_layers=15, mlp_num_layers=2, emb_hidden_channels=256, gnn_hidden_channels=256, mlp_hidden_channels=256, dropout=0.3, grad_clip_norm=2.0, batch_size=65536, lr=0.001, num_neg=1, walk_length=5, epochs=500, log_steps=1, eval_steps=5, runs=1, year=2010, use_lr_decay=False, use_node_feats=False, use_coalesce=False, train_node_emb=False, use_valedges_as_input=False, eval_last_best=False, random_walk_augment=False, alpha=0.5, init='NPPR')
Total number of model parameters is 60514065
Hits@20
Run: 01, Epoch: 05, Loss: 16440.7759, Learning Rate: 0.0010, Valid: 2.97%, Test: 2.93%
Hits@50
Run: 01, Epoch: 05, Loss: 16440.7759, Learning Rate: 0.0010, Valid: 5.60%, Test: 5.57%
Hits@100
Run: 01, Epoch: 05, Loss: 16440.7759, Learning Rate: 0.0010, Valid: 8.55%, Test: 8.38%
Hits@20
Run: 01, Epoch: 10, Loss: 13897.0530, Learning Rate: 0.0010, Valid: 3.30%, Test: 3.32%
Hits@50
Run: 01, Epoch: 10, Loss: 13897.0530, Learning Rate: 0.0010, Valid: 6.55%, Test: 6.45%
Hits@100
Run: 01, Epoch: 10, Loss: 13897.0530, Learning Rate: 0.0010, Valid: 10.53%, Test: 9.76%
