Namespace(device=1, encoder='HLGNN', predictor='MLP', optimizer='Adam', loss_func='AUC', neg_sampler='global', data_name='ogbl-collab', data_path='/home/zhangjuzheng/dataset', eval_metric='hits', walk_start_type='edge', res_dir='log', pretrain_emb=None, gnn_num_layers=15, mlp_num_layers=2, emb_hidden_channels=256, gnn_hidden_channels=256, mlp_hidden_channels=256, dropout=0.3, grad_clip_norm=2.0, batch_size=65536, lr=0.001, num_neg=1, walk_length=5, epochs=500, log_steps=1, eval_steps=5, runs=1, year=2010, use_lr_decay=False, use_node_feats=False, use_coalesce=False, train_node_emb=True, use_valedges_as_input=False, eval_last_best=False, random_walk_augment=False, alpha=0.5, init='NPPR')
Total number of model parameters is 60514065
Hits@20
Run: 01, Epoch: 05, Loss: 16351.1954, Learning Rate: 0.0010, Valid: 3.56%, Test: 3.57%
Hits@50
Run: 01, Epoch: 05, Loss: 16351.1954, Learning Rate: 0.0010, Valid: 6.73%, Test: 6.66%
Hits@100
Run: 01, Epoch: 05, Loss: 16351.1954, Learning Rate: 0.0010, Valid: 9.93%, Test: 9.66%
Hits@20
Run: 01, Epoch: 10, Loss: 13723.7387, Learning Rate: 0.0010, Valid: 3.79%, Test: 3.74%
Hits@50
Run: 01, Epoch: 10, Loss: 13723.7387, Learning Rate: 0.0010, Valid: 7.79%, Test: 7.23%
Hits@100
Run: 01, Epoch: 10, Loss: 13723.7387, Learning Rate: 0.0010, Valid: 10.95%, Test: 9.77%
Hits@20
Run: 01, Epoch: 15, Loss: 9109.7730, Learning Rate: 0.0010, Valid: 2.54%, Test: 2.48%
Hits@50
Run: 01, Epoch: 15, Loss: 9109.7730, Learning Rate: 0.0010, Valid: 5.45%, Test: 5.12%
Hits@100
Run: 01, Epoch: 15, Loss: 9109.7730, Learning Rate: 0.0010, Valid: 10.09%, Test: 9.43%
